{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 결합\n",
    "\n",
    "- 컬림이 일치된 각 연도별 데이터에서 결합을 통해 전체 통합 데이터 셋 추출\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Psychosocial_data\n",
      "(112, 171) (145, 172) (222, 172) (222, 172) (259, 172) (287, 172) (287, 172) (287, 172) (202, 172)\n",
      "Blood_data\n",
      "(112, 44) (145, 44) (222, 44) (222, 44) (259, 44) (287, 44) (287, 44) (287, 44) (202, 44)\n",
      "(112, 171) (145, 172) (222, 172) (222, 172) (259, 172) (287, 172) (287, 172) (287, 172) (202, 172)\n",
      "(112, 190) (145, 191) (222, 191) (222, 191) (259, 191) (287, 191) (287, 191) (287, 191) (202, 191)\n",
      "(2023, 191)\n"
     ]
    }
   ],
   "source": [
    "# df_15 에서 FSSQ_13을 -> 14로 변경\n",
    "df_15_1 = pd.read_csv(\"../../data/blood_df_15.csv\",index_col = 0)\n",
    "df_16_1 = pd.read_csv(\"../../data/blood_df_16.csv\",index_col = 0)\n",
    "df_17_1 = pd.read_csv(\"../../data/blood_df_17.csv\",index_col = 0)\n",
    "df_18_1 = pd.read_csv(\"../../data/blood_df_18.csv\",index_col = 0)\n",
    "df_19_1 = pd.read_csv(\"../../data/blood_df_19.csv\",index_col = 0)\n",
    "df_20_1 = pd.read_csv(\"../../data/blood_df_20.csv\",index_col = 0)\n",
    "df_21_1 = pd.read_csv(\"../../data/blood_df_21.csv\",index_col = 0)\n",
    "df_22_1 = pd.read_csv(\"../../data/blood_df_22.csv\",index_col = 0)\n",
    "df_23_1 = pd.read_csv(\"../../data/blood_df_23.csv\",index_col = 0)\n",
    "\n",
    "df_15 = pd.read_csv(\"../../data/Psychosocial_df_15.csv\",index_col = 0)\n",
    "df_16 = pd.read_csv(\"../../data/Psychosocial_df_16.csv\",index_col = 0)\n",
    "df_17 = pd.read_csv(\"../../data/Psychosocial_df_17.csv\",index_col = 0)\n",
    "df_18 = pd.read_csv(\"../../data/Psychosocial_df_18.csv\",index_col = 0)\n",
    "df_19 = pd.read_csv(\"../../data/Psychosocial_df_19.csv\",index_col = 0)\n",
    "df_20 = pd.read_csv(\"../../data/Psychosocial_df_20.csv\",index_col = 0)\n",
    "df_21 = pd.read_csv(\"../../data/Psychosocial_df_21.csv\",index_col = 0)\n",
    "df_22 = pd.read_csv(\"../../data/Psychosocial_df_22.csv\",index_col = 0)\n",
    "df_23 = pd.read_csv(\"../../data/Psychosocial_df_23.csv\",index_col = 0)\n",
    "\n",
    "df_15['Date'] = 15\n",
    "df_16['Date'] = 16\n",
    "df_17['Date'] = 17\n",
    "df_18['Date'] = 18\n",
    "df_19['Date'] = 19\n",
    "df_20['Date'] = 20\n",
    "df_21['Date'] = 21\n",
    "df_22['Date'] = 22\n",
    "df_23['Date'] = 23\n",
    "\n",
    "df_15_1 = df_15_1.dropna(subset=['번호'])\n",
    "df_16_1 = df_16_1.dropna(subset=['번호'])\n",
    "df_17_1 = df_17_1.dropna(subset=['번호'])\n",
    "df_18_1 = df_18_1.dropna(subset=['번호'])\n",
    "df_19_1 = df_19_1.dropna(subset=['번호'])\n",
    "df_20_1 = df_20_1.dropna(subset=['번호'])\n",
    "df_21_1 = df_21_1.dropna(subset=['번호'])\n",
    "df_22_1 = df_22_1.dropna(subset=['번호'])\n",
    "df_23_1 = df_23_1.dropna(subset=['번호'])\n",
    "\n",
    "print(\"Psychosocial_data\")\n",
    "\n",
    "print(\n",
    "      df_15.shape,\n",
    "      df_16.shape,\n",
    "      df_17.shape,\n",
    "      df_18.shape,\n",
    "      df_19.shape,\n",
    "      df_20.shape,\n",
    "      df_21.shape,\n",
    "      df_22.shape,\n",
    "      df_23.shape,)\n",
    "\n",
    "print(\"Blood_data\")\n",
    "print(\n",
    "      df_15_1.shape,\n",
    "      df_16_1.shape,\n",
    "      df_17_1.shape,\n",
    "      df_18_1.shape,\n",
    "      df_19_1.shape,\n",
    "      df_20_1.shape,\n",
    "      df_21_1.shape,\n",
    "      df_22_1.shape,\n",
    "      df_23_1.shape,)\n",
    "\n",
    "# 중복되는 컬럼들 제거\n",
    "def concatenate_dfs(df, df_1):\n",
    "    # df_1 중복제거\n",
    "    df_1_unique = df_1.loc[:, ~df_1.columns.isin(df.columns)]\n",
    "    # 데이터 컬럼 결합\n",
    "    return pd.concat([df, df_1_unique], axis=1)\n",
    "\n",
    "df_15_combined = concatenate_dfs(df_15, df_15_1)\n",
    "df_16_combined = concatenate_dfs(df_16, df_16_1)\n",
    "df_17_combined = concatenate_dfs(df_17, df_17_1)\n",
    "df_18_combined = concatenate_dfs(df_18, df_18_1)\n",
    "df_19_combined = concatenate_dfs(df_19, df_19_1)\n",
    "df_20_combined = concatenate_dfs(df_20, df_20_1)\n",
    "df_21_combined = concatenate_dfs(df_21, df_21_1)\n",
    "df_22_combined = concatenate_dfs(df_22, df_22_1)\n",
    "df_23_combined = concatenate_dfs(df_23, df_23_1)\n",
    "\n",
    "\n",
    "print(\n",
    "      df_15.shape,\n",
    "      df_16.shape,\n",
    "      df_17.shape,\n",
    "      df_18.shape,\n",
    "      df_19.shape,\n",
    "      df_20.shape,\n",
    "      df_21.shape,\n",
    "      df_22.shape,\n",
    "      df_23.shape,)\n",
    "\n",
    "print(\n",
    "      df_15_combined.shape,\n",
    "      df_16_combined.shape,\n",
    "      df_17_combined.shape,\n",
    "      df_18_combined.shape,\n",
    "      df_19_combined.shape,\n",
    "      df_20_combined.shape,\n",
    "      df_21_combined.shape,\n",
    "      df_22_combined.shape,\n",
    "      df_23_combined.shape,)\n",
    "\n",
    "total_data_set = pd.concat([df_15_combined,df_16_combined,df_17_combined,df_18_combined,df_19_combined,df_20,\n",
    "                            df_21_combined,df_22_combined,df_23_combined])\n",
    "\n",
    "print(total_data_set.shape)\n",
    "total_data_set.to_csv(\"../../data/test_preprocess_1_total_data.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PTSD score를 통한 정재 진행(Label)\n",
    "\n",
    "- PTSD score중 2개 이상 null 환자 제거\n",
    "- PTSD score에서 1개가 null 일경우\n",
    "  - 각 행의 평균을 계산하고, NA를 행의 평균의 올림 값으로 대체\n",
    "- 전체 설문지 조사도 같은 방식으로 적용\n",
    "- 각 설문지의 설문지 총합 구한후 제거\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "493\n",
      "1530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/44/6_rc724s369980pjcph8pltr0000gp/T/ipykernel_52715/3997132418.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_data_set_1[PTSD_name] = PTSD_data_filled\n"
     ]
    }
   ],
   "source": [
    "# PTSD 중 2개 이상인 환자 제거\n",
    "PTSD_name = [\"PTSD 1\",\"PTSD 2\",\"PTSD 3\",\"PTSD 4\",\"PTSD 5\",\"PTSD 6\",\n",
    "             \"PTSD 7\",\"PTSD 8\",\"PTSD 9\",\"PTSD 10\",\"PTSD 11\",\"PTSD 12\",\n",
    "             \"PTSD 13\",\"PTSD 14\",\"PTSD 15\",\"PTSD 16\",\"PTSD 17\",\"PTSD 18\",\n",
    "             \"PTSD 19\",\"PTSD 20\"]\n",
    "\n",
    "# PTSD score , 가 있을 경우 뒤에있는 score\n",
    "# PTSD . -> Na값 처리\n",
    "\n",
    "for column in PTSD_name:\n",
    "    # '.' 포함 시 NA 대체\n",
    "    total_data_set[column] = total_data_set[column].apply(lambda x: np.nan if x == '.' else x)\n",
    "    # ',' 포함 시 쉼표 뒤 값만 추출\n",
    "    total_data_set[column] = total_data_set[column].apply(lambda x: int(x.split(',')[-1]) if ',' in str(x) else x)\n",
    "\n",
    "\n",
    "# PTSD Null 값 2개 이상인 환자 데이터\n",
    "elim_pat = total_data_set[total_data_set[PTSD_name].isnull().sum(axis=1) >= 2]\n",
    "print(len(elim_pat))\n",
    "check_data = total_data_set[total_data_set[PTSD_name].isnull().sum(axis=1) <= 1]\n",
    "print(len(check_data))\n",
    "\n",
    "total_data_set_1= total_data_set[total_data_set[PTSD_name].isnull().sum(axis=1) < 2]\n",
    "total_data_set_1.shape\n",
    "\n",
    "PTSD_data = total_data_set_1[PTSD_name]\n",
    "\n",
    "PTSD_data = PTSD_data.astype(float)\n",
    "\n",
    "# 각 행의 평균을 계산하고, NA를 행의 평균의 올림 값으로 대체\n",
    "PTSD_data_filled = PTSD_data.apply(lambda row: row.fillna(math.ceil(row.mean())) if not np.isnan(row.mean()) else row, axis=1)\n",
    "\n",
    "# 처리된 데이터를 원래 데이터프레임에 다시 병합\n",
    "total_data_set_1[PTSD_name] = PTSD_data_filled"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리 (Psychosocial data preprocess)\n",
    "\n",
    "- '.' 포함 시 NA 대체\n",
    "- ',' 포함 시 쉼표 뒤 값만 추출\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/44/6_rc724s369980pjcph8pltr0000gp/T/ipykernel_52715/4105463341.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_data_set_1[existing_columns] = (\n",
      "/var/folders/44/6_rc724s369980pjcph8pltr0000gp/T/ipykernel_52715/4105463341.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_data_set_1.drop(columns = \"FSSQ_13\",inplace = True)\n",
      "/var/folders/44/6_rc724s369980pjcph8pltr0000gp/T/ipykernel_52715/4105463341.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_data_set_1[column_list] = fill_na_with_mean_condition(total_data_set_1, column_list)\n",
      "/var/folders/44/6_rc724s369980pjcph8pltr0000gp/T/ipykernel_52715/4105463341.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_data_set_1[column_list] = fill_na_with_mean_condition(total_data_set_1, column_list)\n",
      "/var/folders/44/6_rc724s369980pjcph8pltr0000gp/T/ipykernel_52715/4105463341.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_data_set_1[column_list] = fill_na_with_mean_condition(total_data_set_1, column_list)\n",
      "/var/folders/44/6_rc724s369980pjcph8pltr0000gp/T/ipykernel_52715/4105463341.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_data_set_1[column_list] = fill_na_with_mean_condition(total_data_set_1, column_list)\n",
      "/var/folders/44/6_rc724s369980pjcph8pltr0000gp/T/ipykernel_52715/4105463341.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_data_set_1[column_list] = fill_na_with_mean_condition(total_data_set_1, column_list)\n",
      "/var/folders/44/6_rc724s369980pjcph8pltr0000gp/T/ipykernel_52715/4105463341.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_data_set_1[column_list] = fill_na_with_mean_condition(total_data_set_1, column_list)\n",
      "/var/folders/44/6_rc724s369980pjcph8pltr0000gp/T/ipykernel_52715/4105463341.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_data_set_1[column_list] = fill_na_with_mean_condition(total_data_set_1, column_list)\n",
      "/var/folders/44/6_rc724s369980pjcph8pltr0000gp/T/ipykernel_52715/4105463341.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_data_set_1[column_list] = fill_na_with_mean_condition(total_data_set_1, column_list)\n",
      "/var/folders/44/6_rc724s369980pjcph8pltr0000gp/T/ipykernel_52715/4105463341.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_data_set_1[column_list] = fill_na_with_mean_condition(total_data_set_1, column_list)\n",
      "/var/folders/44/6_rc724s369980pjcph8pltr0000gp/T/ipykernel_52715/4105463341.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_data_set_1[column_list] = fill_na_with_mean_condition(total_data_set_1, column_list)\n",
      "/var/folders/44/6_rc724s369980pjcph8pltr0000gp/T/ipykernel_52715/4105463341.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_data_set_1[column_list] = fill_na_with_mean_condition(total_data_set_1, column_list)\n",
      "/var/folders/44/6_rc724s369980pjcph8pltr0000gp/T/ipykernel_52715/4105463341.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_data_set_1[column_list] = fill_na_with_mean_condition(total_data_set_1, column_list)\n"
     ]
    }
   ],
   "source": [
    "PTSD_name = [\"PTSD 1\", \"PTSD 2\", \"PTSD 3\", \"PTSD 4\", \"PTSD 5\", \"PTSD 6\",\n",
    "             \"PTSD 7\", \"PTSD 8\", \"PTSD 9\", \"PTSD 10\", \"PTSD 11\", \"PTSD 12\", \n",
    "             \"PTSD 13\", \"PTSD 14\", \"PTSD 15\", \"PTSD 16\", \"PTSD 17\", \"PTSD 18\",\n",
    "             \"PTSD 19\", \"PTSD 20\"]\n",
    "\n",
    "PTGI_name = [\"PTGI 1\", \"PTGI 2\", \"PTGI 3\", \"PTGI 4\", \"PTGI 5\", \n",
    "             \"PTGI 6\", \"PTGI 7\", \"PTGI 8\", \"PTGI 9\", \"PTGI 10\"]\n",
    "\n",
    "GAD_name = [\"GAD_ 1\", \"GAD_ 2\", \"GAD_ 3\", \"GAD_ 4\", \"GAD_ 5\", \"GAD_ 6\", \"GAD_ 7\"]\n",
    "\n",
    "ISS_name = [\"ISS1_1\", \"ISS1_2\", \"ISS1_3\", \"ISS2\", \"ISS3\", \"ISS4\", \"ISS5\"]\n",
    "\n",
    "\n",
    "PHQ_name = [\"PHQ9_1\", \"PHQ9_2\", \"PHQ9_3\", \"PHQ9_4\", \"PHQ9_5\", \"PHQ9_6\", \n",
    "            \"PHQ9_7\", \"PHQ9_8\", \"PHQ9_9\"]\n",
    "\n",
    "SF_name = [\"SF_1\", \"SF_2\", \"SF_3\", \"SF_4\", \"SF_5\", \"SF_6\", \"SF_7\", \"SF_8\"]\n",
    "\n",
    "FSSQ_name = [\"FSSQ_1\", \"FSSQ_2\", \"FSSQ_3\", \"FSSQ_4\", \"FSSQ_5\", \"FSSQ_6\", \n",
    "             \"FSSQ_7\", \"FSSQ_8\", \"FSSQ_9\", \"FSSQ_10\", \"FSSQ_11\", \"FSSQ_12\",\n",
    "             \"FSSQ_14\"]\n",
    "\n",
    "\n",
    "ECR_name = [\"ECR-S_1\", \"ECR-S_2\", \"ECR-S_3\", \"ECR-S_4\", \"ECR-S_5\", \"ECR-S_6\", \n",
    "            \"ECR-S_7\", \"ECR-S_8\", \"ECR-S_9\", \"ECR-S_10\", \"ECR-S_11\", \n",
    "            \"ECR-S_12\"]\n",
    "\n",
    "ERR_name = [\"K-ERRI_1\", \"K-ERRI_2\", \"K-ERRI_3\", \"K-ERRI_4\", \n",
    "            \"K-ERRI_5\", \"K-ERRI_6\", \"K-ERRI_7\", \"K-ERRI_8\", \"K-ERRI_9\", \n",
    "            \"K-ERRI_10\", \"K-ERRI_11\", \"K-ERRI_12\", \"K-ERRI_13\", \"K-ERRI_14\",\n",
    "            \"K-ERRI_15\", \"K-ERRI_16\", \"K-ERRI_17\", \"K-ERRI_18\", \"K-ERRI_19\", \n",
    "            \"K-ERRI_20\"]\n",
    "\n",
    "\n",
    "B_COPE_name = [\"B-COPE_1\", \"B-COPE_2\", \"B-COPE_3\", \"B-COPE_4\", \"B-COPE_5\", \n",
    "               \"B-COPE_6\", \"B-COPE_7\", \"B-COPE_8\", \"B-COPE_9\", \"B-COPE_10\", \n",
    "               \"B-COPE_11\", \"B-COPE_12\", \"B-COPE_13\", \"B-COPE_14\", \"B-COPE_15\", \n",
    "               \"B-COPE_16\", \"B-COPE_17\", \"B-COPE_18\", \"B-COPE_19\", \"B-COPE_20\", \n",
    "               \"B-COPE_21\", \"B-COPE_22\", \"B-COPE_23\", \"B-COPE_24\", \"B-COPE_25\", \n",
    "               \"B-COPE_26\", \"B-COPE_27\", \"B-COPE_28\"]\n",
    "\n",
    "\n",
    "GARS_name = [\"GARS1\", \"GARS2\", \"GARS3\", \"GARS4\", \"GARS5\", \"GARS6\", \"GARS7\", \n",
    "             \"GARS8\"]\n",
    "\n",
    "\n",
    "POREST_name = [\"POREST_1\", \"POREST_2\", \"POREST_3\", \"POREST_4\", \"POREST_5\", \n",
    "               \"POREST_6\", \"POREST_7\", \"POREST_8\", \"POREST_9\", \"POREST_10\", \n",
    "               \"POREST_11\", \"POREST_12\", \"POREST_13\", \"POREST_14\", \"POREST_15\", \n",
    "               \"POREST_16\", \"POREST_17\", \"POREST_18\", \"POREST_19\", \"POREST_20\", \n",
    "               \"POREST_21\", \"POREST_22\", \"POREST_23\"]\n",
    "\n",
    "###############################################################################################################################################################################################################\n",
    "\n",
    "# 모든 컬럼 이름 리스트를 하나로 합치기\n",
    "all_columns = (\n",
    "    PTSD_name + PTGI_name + ISS_name + GAD_name + PHQ_name + SF_name +\n",
    "    FSSQ_name + ECR_name + ERR_name + B_COPE_name + GARS_name + POREST_name\n",
    ")\n",
    "\n",
    "# 데이터프레임에 존재하는 컬럼만 선택\n",
    "existing_columns = [col for col in all_columns if col in total_data_set_1.columns]\n",
    "\n",
    "# 컬럼 데이터 처리\n",
    "total_data_set_1[existing_columns] = (\n",
    "    total_data_set_1[existing_columns]\n",
    "    .replace('.', np.nan)  # '.'을 np.nan으로 대체\n",
    "    .astype(str)           # 데이터를 문자열로 변환\n",
    "    .apply(lambda x: x.str.split(',').str[-1])  # ','로 분할하여 마지막 값 추출\n",
    "    .apply(pd.to_numeric, errors='coerce')      # 숫자로 변환 (변환 불가 시 NaN)\n",
    ")\n",
    "\n",
    "total_data_set_1.drop(columns = \"FSSQ_13\",inplace = True)\n",
    "\n",
    "\n",
    "# 리스트를 하나로 묶기\n",
    "all_columns = [PTSD_name, PTGI_name, GAD_name, ISS_name, PHQ_name, SF_name, \n",
    "               FSSQ_name, ECR_name, ERR_name, B_COPE_name, GARS_name, POREST_name]\n",
    "\n",
    "\n",
    "# 각 리스트에 대해 처리하는 함수 정의\n",
    "def fill_na_with_mean_condition(df, column_list):\n",
    "    # 선택한 컬럼들에 대해서 빈 문자열과 공백을 NaN으로 변환한 후, 숫자로 변환\n",
    "    data = df[column_list].replace(r'^\\s*$', np.nan, regex=True)\n",
    "    \n",
    "    # 변환할 수 없는 값이 남아있는지 확인\n",
    "    for col in column_list:\n",
    "        # 변환할 수 없는 값 확인\n",
    "        non_convertible = data[col].apply(pd.to_numeric, errors='coerce').isna() & data[col].notna()\n",
    "        if non_convertible.any():\n",
    "            print(f\"컬럼 '{col}'에 변환할 수 없는 값이 존재합니다: {data[col][non_convertible].unique()}\")\n",
    "\n",
    "    # NaN이 아닌 값은 float으로 변환\n",
    "    data = data.astype(float)\n",
    "    \n",
    "    # 각 행에서 null 값이 1개인 경우에만 평균으로 대체\n",
    "    def fill_na_with_mean(row):\n",
    "        if row.isnull().sum() == 1:  # null 값이 1개인 경우\n",
    "            mean_value = row.mean()\n",
    "            if not np.isnan(mean_value):  # 평균이 NaN이 아닌 경우\n",
    "                return row.fillna(math.ceil(mean_value))\n",
    "        return row  # 조건에 맞지 않는 경우 원래 값을 반환\n",
    "    \n",
    "    return data.apply(fill_na_with_mean, axis=1)\n",
    "\n",
    "# 원래 데이터프레임에서 각 리스트에 대해 적용\n",
    "for column_list in all_columns:\n",
    "    total_data_set_1[column_list] = fill_na_with_mean_condition(total_data_set_1, column_list)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정신질환 전처리과정\n",
    "\n",
    "- Psychosocial 설문조사중 각 항목별로 2개 이상의 누락이 있을 경우 환자 제외하고, 1개의 누락값이 있을 경우 누락값을 제외한 평균값의 올림을 적용한 imputation 진행\n",
    "- 사건 반추(ERRI)의 경우 침습적 반추 (1 ~ 10번), 의도적 반추(11 ~ 20번)으로 분류 진행\n",
    "- 단축형 대처기술척도(COPE)의 경우 문제 중심적 대처(6문항), 정서 중심적 대처 (10문항), 회피대처(12문항)으로 분류 진행\n",
    "- ECR, POREST,COPE의 경우 초진에만 설문을 진행하기 때문에, 모든 값을 초진값 혹은 2번 조사를 받은 환자의 경우는 평균값으로 imputation 진행\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/44/6_rc724s369980pjcph8pltr0000gp/T/ipykernel_52715/1576678585.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_data_set_1[total_name] = total_data_set_1[columns].sum(axis=1, skipna=False)\n",
      "/var/folders/44/6_rc724s369980pjcph8pltr0000gp/T/ipykernel_52715/1576678585.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_data_set_1[total_name] = total_data_set_1[columns].sum(axis=1, skipna=False)\n",
      "/var/folders/44/6_rc724s369980pjcph8pltr0000gp/T/ipykernel_52715/1576678585.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_data_set_1[total_name] = total_data_set_1[columns].sum(axis=1, skipna=False)\n",
      "/var/folders/44/6_rc724s369980pjcph8pltr0000gp/T/ipykernel_52715/1576678585.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_data_set_1[total_name] = total_data_set_1[columns].sum(axis=1, skipna=False)\n",
      "/var/folders/44/6_rc724s369980pjcph8pltr0000gp/T/ipykernel_52715/1576678585.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_data_set_1[total_name] = total_data_set_1[columns].sum(axis=1, skipna=False)\n",
      "/var/folders/44/6_rc724s369980pjcph8pltr0000gp/T/ipykernel_52715/1576678585.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_data_set_1[total_name] = total_data_set_1[columns].sum(axis=1, skipna=False)\n",
      "/var/folders/44/6_rc724s369980pjcph8pltr0000gp/T/ipykernel_52715/1576678585.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_data_set_1[total_name] = total_data_set_1[columns].sum(axis=1, skipna=False)\n",
      "/var/folders/44/6_rc724s369980pjcph8pltr0000gp/T/ipykernel_52715/1576678585.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_data_set_1[total_name] = total_data_set_1[columns].sum(axis=1, skipna=False)\n",
      "/var/folders/44/6_rc724s369980pjcph8pltr0000gp/T/ipykernel_52715/1576678585.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_data_set_1[total_name] = total_data_set_1[columns].sum(axis=1, skipna=False)\n",
      "/var/folders/44/6_rc724s369980pjcph8pltr0000gp/T/ipykernel_52715/1576678585.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_data_set_1[total_name] = total_data_set_1[columns].sum(axis=1, skipna=False)\n",
      "/var/folders/44/6_rc724s369980pjcph8pltr0000gp/T/ipykernel_52715/1576678585.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_data_set_1[total_name] = total_data_set_1[columns].sum(axis=1, skipna=False)\n",
      "/var/folders/44/6_rc724s369980pjcph8pltr0000gp/T/ipykernel_52715/1576678585.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_data_set_1[total_name] = total_data_set_1[columns].sum(axis=1, skipna=False)\n",
      "/var/folders/44/6_rc724s369980pjcph8pltr0000gp/T/ipykernel_52715/1576678585.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_data_set_1[total_name] = total_data_set_1[columns].sum(axis=1, skipna=False)\n",
      "/var/folders/44/6_rc724s369980pjcph8pltr0000gp/T/ipykernel_52715/1576678585.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_data_set_1[total_name] = total_data_set_1[columns].sum(axis=1, skipna=False)\n",
      "/var/folders/44/6_rc724s369980pjcph8pltr0000gp/T/ipykernel_52715/1576678585.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_data_set_1.drop(columns=columns_to_drop, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# 컬럼 이름을 딕셔너리로 정의\n",
    "column_groups = {\n",
    "    \"PTSD_total\": [\"PTSD 1\", \"PTSD 2\", \"PTSD 3\", \"PTSD 4\", \"PTSD 5\", \"PTSD 6\",\n",
    "                   \"PTSD 7\", \"PTSD 8\", \"PTSD 9\", \"PTSD 10\", \"PTSD 11\", \"PTSD 12\", \n",
    "                   \"PTSD 13\", \"PTSD 14\", \"PTSD 15\", \"PTSD 16\", \"PTSD 17\", \"PTSD 18\",\n",
    "                   \"PTSD 19\", \"PTSD 20\"],\n",
    "    \"PTGI_total\": [\"PTGI 1\", \"PTGI 2\", \"PTGI 3\", \"PTGI 4\", \"PTGI 5\", \n",
    "                   \"PTGI 6\", \"PTGI 7\", \"PTGI 8\", \"PTGI 9\", \"PTGI 10\"],\n",
    "    \"GAD_total\": [\"GAD_ 1\", \"GAD_ 2\", \"GAD_ 3\", \"GAD_ 4\", \"GAD_ 5\", \"GAD_ 6\", \"GAD_ 7\"],\n",
    "    \"ISS_total\": [\"ISS1_1\", \"ISS1_2\", \"ISS1_3\", \"ISS2\", \"ISS3\", \"ISS4\", \"ISS5\"],\n",
    "    \"PHQ_total\": [\"PHQ9_1\", \"PHQ9_2\", \"PHQ9_3\", \"PHQ9_4\", \"PHQ9_5\", \"PHQ9_6\", \n",
    "                  \"PHQ9_7\", \"PHQ9_8\", \"PHQ9_9\"],\n",
    "    \"FSSQ_total\": [\"FSSQ_1\", \"FSSQ_2\", \"FSSQ_3\", \"FSSQ_4\", \"FSSQ_5\", \"FSSQ_6\", \n",
    "                   \"FSSQ_7\", \"FSSQ_8\", \"FSSQ_9\", \"FSSQ_10\", \"FSSQ_11\", \"FSSQ_12\",\n",
    "                   \"FSSQ_14\"],\n",
    "    \"ECR_total\": [\"ECR-S_1\", \"ECR-S_2\", \"ECR-S_3\", \"ECR-S_4\", \"ECR-S_5\", \"ECR-S_6\", \n",
    "                  \"ECR-S_7\", \"ECR-S_8\", \"ECR-S_9\", \"ECR-S_10\", \"ECR-S_11\", \n",
    "                  \"ECR-S_12\"],\n",
    "    \"ERR_1\": [\"K-ERRI_1\", \"K-ERRI_2\", \"K-ERRI_3\", \"K-ERRI_4\",\"K-ERRI_5\", \"K-ERRI_6\", \n",
    "              \"K-ERRI_7\", \"K-ERRI_8\", \"K-ERRI_9\", \"K-ERRI_10\"],\n",
    "    \"ERR_2\": [\"K-ERRI_11\", \"K-ERRI_12\", \"K-ERRI_13\", \"K-ERRI_14\",\"K-ERRI_15\", \n",
    "              \"K-ERRI_16\", \"K-ERRI_17\", \"K-ERRI_18\", \"K-ERRI_19\", \"K-ERRI_20\"],\n",
    "    \"B_COPE_1\": [\"B-COPE_2\",\"B-COPE_4\",\"B-COPE_12\",\"B-COPE_15\",\"B-COPE_16\", \"B-COPE_17\"],\n",
    "    \"B_COPE_2\": [\"B-COPE_1\",\"B-COPE_3\",\"B-COPE_7\",\"B-COPE_10\", \"B-COPE_13\", \"B-COPE_14\",\n",
    "                 \"B-COPE_23\",\"B-COPE_26\", \"B-COPE_27\", \"B-COPE_28\"],\n",
    "    \"B_COPE_3\": [\"B-COPE_5\", \"B-COPE_6\", \"B-COPE_8\", \"B-COPE_9\",\"B-COPE_11\", \n",
    "                 \"B-COPE_18\", \"B-COPE_19\", \"B-COPE_20\",\"B-COPE_21\", \"B-COPE_22\",\n",
    "                 \"B-COPE_24\", \"B-COPE_25\"],\n",
    "    \"GARS_total\": [\"GARS1\", \"GARS2\", \"GARS3\", \"GARS4\", \"GARS5\", \"GARS6\", \"GARS7\", \n",
    "                   \"GARS8\"],\n",
    "    \"POREST_total\": [\"POREST_1\", \"POREST_2\", \"POREST_3\", \"POREST_4\", \"POREST_5\", \n",
    "                     \"POREST_6\", \"POREST_7\", \"POREST_8\", \"POREST_9\", \"POREST_10\", \n",
    "                     \"POREST_11\", \"POREST_12\", \"POREST_13\", \"POREST_14\", \"POREST_15\", \n",
    "                     \"POREST_16\", \"POREST_17\", \"POREST_18\", \"POREST_19\", \"POREST_20\", \n",
    "                     \"POREST_21\", \"POREST_22\", \"POREST_23\"]\n",
    "}\n",
    "\n",
    "# SF_name은 드롭만 하기 때문에 따로 정의\n",
    "SF_name = [\"SF_1\", \"SF_2\", \"SF_3\", \"SF_4\", \"SF_5\", \"SF_6\", \"SF_7\", \"SF_8\"]\n",
    "\n",
    "# 각 그룹의 합계를 계산하고 새로운 컬럼에 저장\n",
    "for total_name, columns in column_groups.items():\n",
    "    total_data_set_1[total_name] = total_data_set_1[columns].sum(axis=1, skipna=False)\n",
    "\n",
    "# 원래의 컬럼들을 삭제\n",
    "columns_to_drop = []\n",
    "for columns in column_groups.values():\n",
    "    columns_to_drop.extend(columns)\n",
    "columns_to_drop.extend(SF_name)  # SF 컬럼들도 삭제\n",
    "\n",
    "total_data_set_1.drop(columns=columns_to_drop, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "번호                               0\n",
       "분류(1)                            0\n",
       "분류(2)                            0\n",
       "성별                               0\n",
       "만 나이                             0\n",
       "Date                             0\n",
       "키                              224\n",
       "체중                             223\n",
       "혈압(수축기)                        224\n",
       "혈압(이완기)                        224\n",
       "HbA1C (당화혈색소)                  223\n",
       "Glucose (FBS|공복혈당)             223\n",
       "Total Cholesterol (총콜레스테롤)     223\n",
       "HDL-Cholesterol                223\n",
       "LDL-Cholesterol 실측정            223\n",
       "Triglyceride (중성지방)            223\n",
       "CRP(HS)                        223\n",
       "SGOT (AST|지오티)                 223\n",
       "SGPT (ALT|지피티)                 223\n",
       "TSH                            223\n",
       "Free T4                        223\n",
       "Total Protein (총단백)            223\n",
       "Albumin (알부민)                  223\n",
       "BUN (혈중요소질소)                   223\n",
       "Creatinine (크레아티닌)             224\n",
       "PTSD_total                       0\n",
       "PTGI_total                      85\n",
       "GAD_total                       73\n",
       "ISS_total                       69\n",
       "PHQ_total                       69\n",
       "FSSQ_total                     106\n",
       "ECR_total                     1407\n",
       "ERR_1                           88\n",
       "ERR_2                           96\n",
       "B_COPE_1                      1253\n",
       "B_COPE_2                      1253\n",
       "B_COPE_3                      1255\n",
       "GARS_total                     122\n",
       "POREST_total                  1252\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data_set_1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_data_set_1 = total_data_set_1.sort_values(by = [\"번호\",\"Date\"])\n",
    "# ECR_total, POREST_total, B_COPE_total 컬럼에 대해 결측값을 앞뒤로 채우는 방식 유지\n",
    "columns_to_impute = ['ECR_total', 'POREST_total', 'B_COPE_1',\"B_COPE_2\",\"B_COPE_3\"]\n",
    "# ECR_total, POREST_total, B_COPE_total 컬럼에 대해 그룹별 평균의 올림값으로 결측치 채움\n",
    "total_data_set_1[columns_to_impute] = total_data_set_1.groupby('번호')[columns_to_impute].transform(lambda x: x.fillna(np.ceil(x.mean())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "번호                              0\n",
       "분류(1)                           0\n",
       "분류(2)                           0\n",
       "성별                              0\n",
       "만 나이                            0\n",
       "Date                            0\n",
       "키                             224\n",
       "체중                            223\n",
       "혈압(수축기)                       224\n",
       "혈압(이완기)                       224\n",
       "HbA1C (당화혈색소)                 223\n",
       "Glucose (FBS|공복혈당)            223\n",
       "Total Cholesterol (총콜레스테롤)    223\n",
       "HDL-Cholesterol               223\n",
       "LDL-Cholesterol 실측정           223\n",
       "Triglyceride (중성지방)           223\n",
       "CRP(HS)                       223\n",
       "SGOT (AST|지오티)                223\n",
       "SGPT (ALT|지피티)                223\n",
       "TSH                           223\n",
       "Free T4                       223\n",
       "Total Protein (총단백)           223\n",
       "Albumin (알부민)                 223\n",
       "BUN (혈중요소질소)                  223\n",
       "Creatinine (크레아티닌)            224\n",
       "PTSD_total                      0\n",
       "PTGI_total                     85\n",
       "GAD_total                      73\n",
       "ISS_total                      69\n",
       "PHQ_total                      69\n",
       "FSSQ_total                    106\n",
       "ECR_total                     795\n",
       "ERR_1                          88\n",
       "ERR_2                          96\n",
       "B_COPE_1                       54\n",
       "B_COPE_2                       57\n",
       "B_COPE_3                       64\n",
       "GARS_total                    122\n",
       "POREST_total                   48\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data_set_1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_set_1.to_csv(\"../../data/data_preprocess_Psychosocial.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blood Data_preprocess\n",
    "\n",
    "- 모든 컬럼에 대해 '<' 기호가 있는 값을 처리\n",
    "- colums 영문화\n",
    "- PTSD total score 만들기\n",
    "- 고, 저 혈압 -> 평균혈압 만들기\n",
    "- PTSD 필요한 Blood Feature 선정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/data_preprocess_Psychosocial.csv\",index_col = 0)\n",
    "df = df.sort_values(by=['번호', 'Date'], ascending=[True, True])\n",
    "# '<' 기호를 제거하고 그 뒤의 값을 유지하는 함수\n",
    "def remove_less_than_sign(x):\n",
    "    if isinstance(x, str) and '<' in x:\n",
    "        return x.split('<')[-1]\n",
    "    return x\n",
    "\n",
    "# 모든 컬럼에 대해 '<' 기호가 있는 값을 처리\n",
    "for column in df.columns:\n",
    "    df[column] = df[column].apply(remove_less_than_sign)\n",
    "    \n",
    "for column in df.columns:\n",
    "    df[column] = df[column].apply(lambda x: np.nan if x == '.' else x)\n",
    "    \n",
    "df = df.sort_values(by = [\"번호\",\"Date\"])\n",
    "\n",
    "\n",
    "def check_for_string_values(df):\n",
    "    # 수치형 데이터에 문자열이 섞인 열들을 찾음\n",
    "    for column in df.columns:\n",
    "        # 열에서 숫자로 변환할 수 없는 값이 있는지 확인\n",
    "        non_numeric = pd.to_numeric(df[column], errors='coerce').isna() & df[column].notna()\n",
    "        if non_numeric.any():\n",
    "            print(f\"문제가 있는 컬럼: {column}\")\n",
    "            print(f\"문제가 있는 값들: {df[column][non_numeric].unique()}\")\n",
    "            \n",
    "# 원래 데이터프레임 df에서 수치형 값에 문자열이 섞여있는지 확인\n",
    "check_for_string_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/44/6_rc724s369980pjcph8pltr0000gp/T/ipykernel_52715/854861122.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(columns=elim, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "def data_prerocess(df):\n",
    "    df[\"유가족유무\"] = df[\"분류(1)\"] - 1\n",
    "    df.drop(columns= [\"분류(1)\"],inplace= True)\n",
    "    \n",
    "    df[\"성별\"] = df[\"성별\"] - 1\n",
    "\n",
    "    \n",
    "    # naming\n",
    "    kor_eng = {\n",
    "    \"성별\" : \"sex\",\n",
    "    \"만 나이\" : \"age\",\n",
    "#    \"비만도\" : \"BMI\",\n",
    "    \"혈압(수축기)\" : \"low_press\",\n",
    "    \"혈압(이완기)\" : \"high_press\",\n",
    "    \"HbA1C (당화혈색소)\" : \"HbA1C\",\n",
    "    \"Glucose (FBS|공복혈당)\" : \"FBS\",\n",
    "    \"Total Cholesterol (총콜레스테롤)\" : \"Total_Cholesterol\",\n",
    "    \"HDL-Cholesterol\" : \"HDL\",\n",
    "    \"LDL-Cholesterol 실측정\" : \"LDL\",\n",
    "    \"Triglyceride (중성지방)\" : \"TG\",\n",
    "    \"CRP(HS)\" : \"CRP\",\n",
    "    \"SGOT (AST|지오티)\" : \"SGOT\",\n",
    "    \"SGPT (ALT|지피티)\" : \"SGPT\",\n",
    "#    \"Na (나트륨)\" : \"Na\",\n",
    "#    \"K (칼륨)\" : \"K\",\n",
    "#    \"Cl (염소)\" : \"CL\",\n",
    "    \"Free T4\" : \"Free_T4\",\n",
    "    \"RI-Insulin[Basal]\" : \"Insulin\",\n",
    "    \"Total Protein (총단백)\" : \"Protein\",\n",
    "    \"Albumin (알부민)\" : \"Albumin\",\n",
    "    \"BUN (혈중요소질소)\" : \"BUN\",\n",
    "    \"Creatinine (크레아티닌)\" : \"Creatinine\",\n",
    "    \"유가족유무\" : \"is_family\",\n",
    "    \"2촌이하유무\" : \"with_live\",\n",
    "#    \"25-OH Vitamin D total\" : \"Vitamin_D\"\n",
    "    }\n",
    "    \n",
    "    df.rename(columns=kor_eng,inplace=True)    \n",
    "    df['low_press'] = df['low_press'].astype(float)\n",
    "    df['high_press'] = df['high_press'].astype(float)\n",
    "    df['avg_press'] = (df['low_press'] + df['high_press']) / 2.\n",
    "    df['체중'] = df['체중'].astype(float)\n",
    "    df['키'] = df['키'].astype(float)\n",
    "    df[\"BMI\"] = df[\"체중\"]/(df[\"키\"]*0.01)**2\n",
    "    # \n",
    "    df.drop(columns=['low_press', 'high_press'], inplace=True)\n",
    "    df.drop(columns=['체중', '키'], inplace=True)\n",
    "    df.drop(columns=[\"Total_Cholesterol\", \"FBS\"],inplace = True)\n",
    "    \n",
    "    elim = [\"분류(2)\"]\n",
    "    \n",
    "    # target_score를 맨 뒤로\n",
    "    columns = list(df.columns)\n",
    "    columns.append(columns.pop(columns.index('번호')))\n",
    "    \n",
    "    df = df[columns]\n",
    "\n",
    "    df.drop(columns=elim, inplace=True)\n",
    "    \n",
    "         \n",
    "    return df\n",
    "\n",
    "df = data_prerocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex               0\n",
       "age               0\n",
       "Date              0\n",
       "HbA1C           226\n",
       "HDL             226\n",
       "LDL             226\n",
       "TG              226\n",
       "CRP             226\n",
       "SGOT            226\n",
       "SGPT            226\n",
       "TSH             226\n",
       "Free_T4         226\n",
       "Protein         226\n",
       "Albumin         226\n",
       "BUN             226\n",
       "Creatinine      227\n",
       "PTSD_total        0\n",
       "PTGI_total       85\n",
       "GAD_total        73\n",
       "ISS_total        69\n",
       "PHQ_total        69\n",
       "FSSQ_total      106\n",
       "ECR_total       795\n",
       "ERR_1            88\n",
       "ERR_2            96\n",
       "B_COPE_1         54\n",
       "B_COPE_2         57\n",
       "B_COPE_3         64\n",
       "GARS_total      122\n",
       "POREST_total     48\n",
       "is_family         0\n",
       "avg_press       227\n",
       "BMI             227\n",
       "번호                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../../data/ML_data_set.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor-mac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
